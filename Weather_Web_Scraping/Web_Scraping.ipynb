{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping weather data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The role of this notebook is to download weather data for the 100 largest cities in Poland. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import  load_dotenv\n",
    "import os\n",
    "import csv\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading API key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"D:\\Python\\devcontainer\\.env\") #loading API key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEY_OWM = os.getenv(\"OWM_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the city names of the 100 largest cities in Poland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_city_name = 'https://www.jetpunk.com/user-quizzes/1444759/100-najwiekszych-miast-w-polsce/stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = requests.get(url_city_name)\n",
    "soup = BeautifulSoup(web.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.select('table.super-table tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "\n",
    "for row in rows:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 1:\n",
    "        city_name = columns[1].text.strip()\n",
    "        cities.append(city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('cities.csv', 'w', newline='', encoding='utf-8') as cities_names:\n",
    "    write = csv.writer(cities_names)\n",
    "    write.writerow(['City Name'])\n",
    "    for city in cities:\n",
    "        write.writerow([city])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading coordinates of cities using the selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_coordinates_width = []\n",
    "cities_coordinates_length = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_names_csv = []\n",
    "\n",
    "with open('cities.csv', 'r', encoding='utf-8') as cities_names:\n",
    "    next(cities_names)\n",
    "    for single_line in cities_names:\n",
    "        cities_names_csv.append(single_line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading data can take about 13 minutes, this is due to the long response time of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = FirefoxService(r'.\\geckodriver.exe') \n",
    "browser = Firefox(service=service) \n",
    "\n",
    "browser.get('https://bazamiejscowosci.pl')\n",
    "\n",
    "for city in cities_names_csv:\n",
    "    search_box = browser.find_element('id', 'map-search')\n",
    "    search_box.click()\n",
    "    \n",
    "    search_box.send_keys(city)\n",
    "    \n",
    "    time.sleep(3)\n",
    "\n",
    "    button = browser.find_element('class name', 'ui-menu-item')\n",
    "    button.click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "    get_coordinates = browser.find_element('id', 'city-decimal')\n",
    "\n",
    "    coordinates = str(get_coordinates.text).split(', ')\n",
    "\n",
    "    cities_coordinates_width.append(coordinates[0])\n",
    "    cities_coordinates_length.append(coordinates[1])\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    browser.get('https://bazamiejscowosci.pl')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a file with coordinates of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates = pd.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates['width'] = cities_coordinates_width\n",
    "\n",
    "df_coordinates['length'] = cities_coordinates_length\n",
    "\n",
    "df_coordinates['City ID'] = df_coordinates.index\n",
    "\n",
    "df_coordinates.to_csv('cities.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading weather data using the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(lat, lon, APIKEY_OWM):\n",
    "    response = requests.get(f'https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&exclude=current&appid={APIKEY_OWM}&units=metric')\n",
    "    currency_data = response.json()\n",
    "    return currency_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(columns=['City ID', 'Date', 'Time', 'Temperature', 'Pressure', 'Humidity', 'main', 'description', 'Clouds', 'speed', 'deg', 'Rain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_pandas(data, df, city_id, przelicznik):\n",
    "    \n",
    "    for time in range(0, 40):\n",
    "        \n",
    "        row = time + (40 * przelicznik)\n",
    "        \n",
    "        # Date and time\n",
    "        \n",
    "        weather_date = data['list'][time]['dt']\n",
    "        utc_date = datetime.utcfromtimestamp(weather_date).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        utc_date = utc_date.split(' ') \n",
    "        df.loc[row, ['Date', 'Time']] = [utc_date[0], utc_date[1]]\n",
    "        \n",
    "        # Temperature\tPressure\tHumidity\n",
    "        \n",
    "        info = data['list'][time]['main']\n",
    "        df.loc[row, ['Temperature', 'Pressure', 'Humidity']] = [info['temp'], info['pressure'], info['humidity']]\n",
    "        \n",
    "        # General\tDescription\n",
    "            \n",
    "        for category in ['main', 'description']:\n",
    "            df.loc[row, [category]] = data['list'][time]['weather'][0][category]\n",
    "        \n",
    "        # Clouds\n",
    "        \n",
    "        df.loc[row, ['Clouds']] = data['list'][time]['clouds']['all']\n",
    "        \n",
    "        # Wind Speed\tWind Deg\n",
    "        \n",
    "        for category in ['speed', 'deg']:\n",
    "            df.loc[row, [category]] = data['list'][time]['wind'][category]\n",
    "\n",
    "        #Rain\n",
    "        \n",
    "        try:\n",
    "            weather_rain = data['list'][time]['rain']['3h']\n",
    "        except KeyError:\n",
    "            df.loc[row, ['Rain']] = 'No rain'\n",
    "        else:   \n",
    "            df.loc[row, ['Rain']] = weather_rain\n",
    "            \n",
    "        df.loc[row, ['City ID']] = city_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_data = pd.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "for city in range(0,100):\n",
    "    city_name = str(cities_data.loc[city, 'City Name'])\n",
    "    width = float(cities_data.loc[city, 'width'])\n",
    "    length = float(cities_data.loc[city, 'length'])\n",
    "    \n",
    "    city_id = cities_data.index[city]\n",
    "\n",
    "    \n",
    "    cities_raw_data = get_data(lat=width, lon=length, APIKEY_OWM=APIKEY_OWM)\n",
    "    \n",
    "    data_to_pandas(data=cities_raw_data, df=weather_df, city_id=city_id, przelicznik=x)\n",
    "\n",
    "    x += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_weather_df = pd.merge(weather_df, cities_data, on='City ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the merged weather data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_weather_df.to_csv('weather_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (websrap)",
   "language": "python",
   "name": "webscrap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
